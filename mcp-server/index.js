#!/usr/bin/env node

import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import {
  CallToolRequestSchema,
  ListToolsRequestSchema,
} from "@modelcontextprotocol/sdk/types.js";
import { spawn } from "child_process";
import fs from "fs";
import path from "path";

// Server configuration
const server = new Server(
  {
    name: "payclip-testing-mcp-server",
    version: "1.0.0",
  },
  {
    capabilities: {
      tools: {},
    },
  }
);

// PayClip Testing Framework root path
const FRAMEWORK_ROOT = path.resolve("../");

// Available environments
const ENVIRONMENTS = ["dev", "stage"];

// Available payment types
const PAYMENT_TYPES = ["HOSTED_CHECKOUT", "LINK_DE_PAGO", "SUBSCRIPTION"];

// Available test modes
const TEST_MODES = ["silent", "verbose"];

/**
 * Execute npm test command with specified parameters
 */
function executeTest(environment, options = {}) {
  return new Promise((resolve, reject) => {
    const { type, just, record, verbose, customArgs } = options;

    // Build command
    let command = `npm run test:${environment}`;
    if (verbose) {
      command = `npm run test:${environment}:verbose`;
    }

    // Build arguments
    const args = [];
    if (type) args.push(`--type=${type}`);
    if (just) args.push(`--just=${just}`);
    if (record) args.push(`--record=${record}`);
    if (customArgs) args.push(...customArgs.split(" "));

    const fullCommand =
      args.length > 0 ? `${command} ${args.join(" ")}` : command;

    console.log(`ðŸš€ Executing: ${fullCommand}`);

    // Execute command
    const child = spawn("sh", ["-c", fullCommand], {
      cwd: FRAMEWORK_ROOT,
      stdio: ["pipe", "pipe", "pipe"],
    });

    let stdout = "";
    let stderr = "";

    child.stdout.on("data", (data) => {
      stdout += data.toString();
    });

    child.stderr.on("data", (data) => {
      stderr += data.toString();
    });

    child.on("close", (code) => {
      if (code === 0) {
        resolve({
          success: true,
          command: fullCommand,
          output: stdout,
          exitCode: code,
        });
      } else {
        reject({
          success: false,
          command: fullCommand,
          output: stdout,
          error: stderr,
          exitCode: code,
        });
      }
    });

    child.on("error", (error) => {
      reject({
        success: false,
        command: fullCommand,
        error: error.message,
        exitCode: -1,
      });
    });
  });
}

/**
 * Get latest test results
 */
function getLatestResults(environment, paymentType) {
  const resultsPath = path.join(
    FRAMEWORK_ROOT,
    "completed_tests",
    "test_runs",
    `${environment.toUpperCase()}-${paymentType.toLowerCase()}`
  );

  if (!fs.existsSync(resultsPath)) {
    return { error: `No results found for ${environment}-${paymentType}` };
  }

  const directories = fs
    .readdirSync(resultsPath)
    .filter((dir) => fs.statSync(path.join(resultsPath, dir)).isDirectory())
    .sort()
    .reverse();

  if (directories.length === 0) {
    return { error: `No test runs found for ${environment}-${paymentType}` };
  }

  const latestDir = directories[0];
  const latestPath = path.join(resultsPath, latestDir);

  // Get Excel file
  const excelFiles = fs
    .readdirSync(latestPath)
    .filter((file) => file.endsWith(".xlsx"));
  const excelFile = excelFiles.length > 0 ? excelFiles[0] : null;

  // Get test case directories
  const testCases = fs
    .readdirSync(latestPath)
    .filter((item) => fs.statSync(path.join(latestPath, item)).isDirectory())
    .map((testCase) => {
      const testCasePath = path.join(latestPath, testCase);
      const files = fs.readdirSync(testCasePath);
      return {
        name: testCase,
        files: files,
        hasLogs: files.includes("logs.json"),
        hasScreenshots: files.some((f) => f.endsWith(".png")),
        hasSuccess: files.includes("success-pay-page.png"),
        hasError: files.includes("error-ocurred.png"),
      };
    });

  return {
    timestamp: latestDir,
    path: latestPath,
    excelReport: excelFile,
    testCases: testCases,
    totalTests: testCases.length,
    successfulTests: testCases.filter((tc) => tc.hasSuccess).length,
    failedTests: testCases.filter((tc) => tc.hasError).length,
  };
}

/**
 * Get available parameters from Excel files
 */
function getAvailableParameters(environment) {
  const paramFile = path.join(FRAMEWORK_ROOT, `parameters_${environment}.xlsx`);

  if (!fs.existsSync(paramFile)) {
    return {
      error: `Parameters file not found: parameters_${environment}.xlsx`,
    };
  }

  // Return file info (actual Excel parsing would require additional library)
  const stats = fs.statSync(paramFile);
  return {
    file: `parameters_${environment}.xlsx`,
    size: stats.size,
    lastModified: stats.mtime,
    path: paramFile,
  };
}

// List available tools
server.setRequestHandler(ListToolsRequestSchema, async () => {
  return {
    tools: [
      {
        name: "run_payclip_test",
        description:
          "Execute PayClip E2E tests with various options and filters",
        inputSchema: {
          type: "object",
          properties: {
            environment: {
              type: "string",
              enum: ENVIRONMENTS,
              description: "Test environment (dev or stage)",
            },
            type: {
              type: "string",
              enum: PAYMENT_TYPES,
              description: "Payment type filter",
            },
            just: {
              type: "number",
              description: "Run only first N tests (1, 2, 3, etc.)",
              minimum: 1,
            },
            record: {
              type: "boolean",
              description: "Enable video recording",
            },
            verbose: {
              type: "boolean",
              description: "Enable verbose logging mode",
            },
            customArgs: {
              type: "string",
              description: "Additional custom arguments",
            },
          },
          required: ["environment"],
        },
      },
      {
        name: "get_test_results",
        description:
          "Get latest test results for specified environment and payment type",
        inputSchema: {
          type: "object",
          properties: {
            environment: {
              type: "string",
              enum: ENVIRONMENTS,
              description: "Test environment (dev or stage)",
            },
            paymentType: {
              type: "string",
              enum: PAYMENT_TYPES,
              description: "Payment type",
            },
          },
          required: ["environment", "paymentType"],
        },
      },
      {
        name: "list_available_tests",
        description:
          "List all available test configurations and current status",
        inputSchema: {
          type: "object",
          properties: {},
        },
      },
      {
        name: "get_test_parameters",
        description:
          "Get available test parameters from Excel configuration files",
        inputSchema: {
          type: "object",
          properties: {
            environment: {
              type: "string",
              enum: ENVIRONMENTS,
              description: "Environment to get parameters for",
            },
          },
          required: ["environment"],
        },
      },
      {
        name: "run_unit_tests",
        description: "Execute unit tests for the framework",
        inputSchema: {
          type: "object",
          properties: {},
        },
      },
      {
        name: "generate_test_command",
        description:
          "Generate the exact npm command for specified test configuration",
        inputSchema: {
          type: "object",
          properties: {
            environment: {
              type: "string",
              enum: ENVIRONMENTS,
              description: "Test environment",
            },
            type: {
              type: "string",
              enum: PAYMENT_TYPES,
              description: "Payment type filter",
            },
            just: {
              type: "number",
              description: "Run only first N tests",
            },
            record: {
              type: "boolean",
              description: "Enable video recording",
            },
            verbose: {
              type: "boolean",
              description: "Enable verbose logging",
            },
          },
          required: ["environment"],
        },
      },
    ],
  };
});

// Handle tool calls
server.setRequestHandler(CallToolRequestSchema, async (request) => {
  const { name, arguments: args } = request.params;

  try {
    switch (name) {
      case "run_payclip_test": {
        const { environment, type, just, record, verbose, customArgs } = args;

        const result = await executeTest(environment, {
          type,
          just,
          record,
          verbose,
          customArgs,
        });

        return {
          content: [
            {
              type: "text",
              text: `âœ… Test execution completed successfully!
              
ðŸš€ **Command**: ${result.command}
ðŸ“Š **Exit Code**: ${result.exitCode}
ðŸ“‹ **Output**:
\`\`\`
${result.output}
\`\`\`

ðŸŽ‰ Check the \`completed_tests/test_runs/\` directory for detailed results and reports.`,
            },
          ],
        };
      }

      case "get_test_results": {
        const { environment, paymentType } = args;
        const results = getLatestResults(environment, paymentType);

        if (results.error) {
          return {
            content: [
              {
                type: "text",
                text: `âŒ **Error**: ${results.error}`,
              },
            ],
          };
        }

        return {
          content: [
            {
              type: "text",
              text: `ðŸ“Š **Latest Results for ${environment.toUpperCase()}-${paymentType}**

ðŸ• **Timestamp**: ${results.timestamp}
ðŸ“ **Path**: ${results.path}
ðŸ“ˆ **Total Tests**: ${results.totalTests}
âœ… **Successful**: ${results.successfulTests}
âŒ **Failed**: ${results.failedTests}
ðŸ“Š **Excel Report**: ${results.excelReport || "Not found"}

ðŸ§ª **Test Cases**:
${results.testCases
  .map(
    (tc) => `
â€¢ **${tc.name}**
  - Logs: ${tc.hasLogs ? "âœ…" : "âŒ"}
  - Screenshots: ${tc.hasScreenshots ? "âœ…" : "âŒ"}
  - Status: ${
    tc.hasSuccess ? "ðŸŽ‰ Success" : tc.hasError ? "ðŸ’” Failed" : "âš ï¸ Unknown"
  }
`
  )
  .join("")}`,
            },
          ],
        };
      }

      case "list_available_tests": {
        const testRunsPath = path.join(
          FRAMEWORK_ROOT,
          "completed_tests",
          "test_runs"
        );
        let availableTests = [];

        if (fs.existsSync(testRunsPath)) {
          availableTests = fs
            .readdirSync(testRunsPath)
            .filter((dir) =>
              fs.statSync(path.join(testRunsPath, dir)).isDirectory()
            );
        }

        return {
          content: [
            {
              type: "text",
              text: `ðŸ§ª **PayClip E2E Testing Framework Overview**

ðŸŒ **Available Environments**: ${ENVIRONMENTS.map((env) =>
                env.toUpperCase()
              ).join(", ")}
ðŸ’³ **Payment Types**: ${PAYMENT_TYPES.join(", ")}
ðŸ”Š **Test Modes**: ${TEST_MODES.join(", ")}

ðŸ“ **Available Test Configurations**:
${
  availableTests.length > 0
    ? availableTests.map((test) => `â€¢ ${test}`).join("\n")
    : "No test results found yet"
}

ðŸš€ **Quick Commands**:
â€¢ \`run_payclip_test\` - Execute tests with custom filters
â€¢ \`get_test_results\` - View latest results
â€¢ \`get_test_parameters\` - Check Excel configurations
â€¢ \`run_unit_tests\` - Execute framework unit tests
â€¢ \`generate_test_command\` - Generate exact npm commands

ðŸ’¡ **Example Combinations**:
â€¢ DEV environment, HOSTED_CHECKOUT type, verbose mode
â€¢ STAGE environment, LINK_DE_PAGO type, first 2 tests only
â€¢ Any environment with video recording enabled`,
            },
          ],
        };
      }

      case "get_test_parameters": {
        const { environment } = args;
        const params = getAvailableParameters(environment);

        if (params.error) {
          return {
            content: [
              {
                type: "text",
                text: `âŒ **Error**: ${params.error}`,
              },
            ],
          };
        }

        return {
          content: [
            {
              type: "text",
              text: `ðŸ“‹ **Test Parameters for ${environment.toUpperCase()}**

ðŸ“„ **File**: ${params.file}
ðŸ“Š **Size**: ${(params.size / 1024).toFixed(2)} KB
ðŸ• **Last Modified**: ${params.lastModified.toISOString()}
ðŸ“ **Path**: ${params.path}

â„¹ï¸ The Excel file contains test cases with:
â€¢ Test case names
â€¢ Card numbers for testing
â€¢ Payment Request IDs
â€¢ Payment types (HOSTED_CHECKOUT, LINK_DE_PAGO, SUBSCRIPTION)
â€¢ Payment flows (GUEST, REGISTER)
â€¢ Amounts and currencies (for HOSTED_CHECKOUT)`,
            },
          ],
        };
      }

      case "run_unit_tests": {
        const result = await executeTest("unit", {});

        return {
          content: [
            {
              type: "text",
              text: `ðŸ§ª **Unit Tests Execution**

ðŸš€ **Command**: npm run unit
ðŸ“Š **Exit Code**: ${result.exitCode}
ðŸ“‹ **Output**:
\`\`\`
${result.output}
\`\`\`

${result.success ? "âœ… Unit tests passed!" : "âŒ Unit tests failed!"}`,
            },
          ],
        };
      }

      case "generate_test_command": {
        const { environment, type, just, record, verbose } = args;

        let command = `npm run test:${environment}`;
        if (verbose) {
          command = `npm run test:${environment}:verbose`;
        }

        const argsList = [];
        if (type) argsList.push(`--type=${type}`);
        if (just) argsList.push(`--just=${just}`);
        if (record) argsList.push(`--record=${record}`);

        const fullCommand =
          argsList.length > 0 ? `${command} ${argsList.join(" ")}` : command;

        return {
          content: [
            {
              type: "text",
              text: `ðŸš€ **Generated Test Command**

\`\`\`bash
${fullCommand}
\`\`\`

ðŸ“‹ **Command Breakdown**:
â€¢ **Environment**: ${environment.toUpperCase()}
â€¢ **Mode**: ${verbose ? "Verbose (full logs)" : "Silent (clean output)"}
${type ? `â€¢ **Payment Type**: ${type}` : ""}
${just ? `â€¢ **Test Limit**: First ${just} tests only` : ""}
${record ? `â€¢ **Video Recording**: Enabled` : ""}

ðŸ’¡ **Alternative with environment variable**:
\`\`\`bash
${verbose ? "VERBOSE_LOGS=true " : ""}${command.replace(":verbose", "")}${
                argsList.length > 0 ? " " + argsList.join(" ") : ""
              }
\`\`\`

ðŸŽ¯ **What this will do**:
- Execute PayClip E2E tests in ${environment.toUpperCase()} environment
- Generate screenshots and ${verbose ? "detailed" : "filtered"} JSON logs
- Create Excel report with results
- Save everything to \`completed_tests/test_runs/\` directory`,
            },
          ],
        };
      }

      default:
        throw new Error(`Unknown tool: ${name}`);
    }
  } catch (error) {
    return {
      content: [
        {
          type: "text",
          text: `âŒ **Error executing ${name}**: ${error.message}`,
        },
      ],
      isError: true,
    };
  }
});

// Start the server
async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error("PayClip Testing MCP Server running on stdio");
}

main().catch((error) => {
  console.error("Fatal error in main():", error);
  process.exit(1);
});
